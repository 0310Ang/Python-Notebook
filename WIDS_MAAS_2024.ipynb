{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 65862,
          "databundleVersionId": 7469115,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vEfTm_iJ0TqY",
        "pYwwdHSd0KEw",
        "y5ixZJqz0KEz",
        "HKY-SdLS0KE4",
        "_QPWUK5a0KE7",
        "SbWsuVTa0KE8",
        "_Rca7ogi0KE8",
        "IBXMn3m-0KE-",
        "mCi1lITU0KE_",
        "HldoV2Ud0KFA",
        "Zjp-GAsw0KFB",
        "a2gi_JDY0KFK",
        "sldv5hNM0KFK",
        "zpYRS0TB0KFL"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Quick Panel**"
      ],
      "metadata": {
        "id": "sPpNwRjqZy8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "random_seed = 37"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDZqdWf2ZxGL",
        "outputId": "c52e8442-000b-4654-b2ba-cfda4a8c48d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Set-up"
      ],
      "metadata": {
        "id": "vEfTm_iJ0TqY"
      }
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'widsdatathon2024-challenge1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F65862%2F7469115%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240202%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240202T123452Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5ea2a6dc6b6083c95b5192151c80938ecf30286709850fe096a811a0269d49e1b0f7bf31747c4d315e4cbc6fb1006d04306c862d5c54a8a0848b554296ea3c63c75d85874fba9a9cab9606adee922685d06ffe592eb4ce09848c2f0c7845d819a933fed4b30ecb63cc60573f2e3c5a500a9393c64907daaaa295ddb48c6698398de536a402b0a7378d4f194b88a41179d3f706b25fe420c4a47fdb4bb7413a6a6be90da1912bf37902cb02368bc8f0fb87cb249fbccdde689afe8024b55838b881dff4e97141ac607021ed210a03d6c39644198805c402bffadfba05f22280562ee0bd63465ee6ab43605d90efbb707f298ffd7b0031d95a78b71dc68300d2a9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "AJ0XZWjm0KEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52659e7a-98e0-4556-d0bb-bea64ec3d36d"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading widsdatathon2024-challenge1, 5281541 bytes compressed\n",
            "[==================================================] 5281541 bytes downloaded\n",
            "Downloaded and uncompressed: widsdatathon2024-challenge1\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "-c1vjsfr02RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe80177-cd3e-4e25-e323-ddf7d49f3a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.7/535.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.1 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Needed Packages\n"
      ],
      "metadata": {
        "id": "pYwwdHSd0KEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap as shap\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import warnings\n",
        "import torch\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:40.496Z",
          "iopub.execute_input": "2024-02-02T12:29:40.496406Z",
          "iopub.status.idle": "2024-02-02T12:29:47.235952Z",
          "shell.execute_reply.started": "2024-02-02T12:29:40.496371Z",
          "shell.execute_reply": "2024-02-02T12:29:47.23475Z"
        },
        "trusted": true,
        "id": "S44d6SBh0KEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Jupyter Widges Package - https://ipywidgets.readthedocs.io/en/stable/index.html\n",
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "import ipywidgets as widgets\n",
        "style = {'description_width': 'initial'}\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 300)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:47.238402Z",
          "iopub.execute_input": "2024-02-02T12:29:47.239114Z",
          "iopub.status.idle": "2024-02-02T12:29:47.246658Z",
          "shell.execute_reply.started": "2024-02-02T12:29:47.23907Z",
          "shell.execute_reply": "2024-02-02T12:29:47.245487Z"
        },
        "trusted": true,
        "id": "ibH2w26d0KEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Train and Test Data Files"
      ],
      "metadata": {
        "id": "y5ixZJqz0KEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wojtkC4iTr_K",
        "outputId": "45bb1f57-55d9-4038-d6e3-d2d6adad33cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "df_train = pd.read_csv(path + \"train_AC.csv\", sep=',')\n",
        "df_test = pd.read_csv(path + \"test_AC.csv\", sep=',')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:47.248009Z",
          "iopub.execute_input": "2024-02-02T12:29:47.248331Z",
          "iopub.status.idle": "2024-02-02T12:29:47.809849Z",
          "shell.execute_reply.started": "2024-02-02T12:29:47.248304Z",
          "shell.execute_reply": "2024-02-02T12:29:47.808689Z"
        },
        "trusted": true,
        "id": "HtX5_Jxz0KE0",
        "outputId": "07d2bc5e-843b-4d46-c130-ed21af5ff51e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/widsdatathon2024-challenge1/test.csv\n",
            "/kaggle/input/widsdatathon2024-challenge1/sample_submission.csv\n",
            "/kaggle/input/widsdatathon2024-challenge1/training.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "## Load the data\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "df_train = pd.read_csv(\"/kaggle/input/widsdatathon2024-challenge1/training.csv\", sep=',')\n",
        "df_test = pd.read_csv(\"/kaggle/input/widsdatathon2024-challenge1/test.csv\", sep=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke3ObG_oT_TW",
        "outputId": "f10a34a1-fcbd-49b0-fbfd-6a41e50188ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/widsdatathon2024-challenge1/test.csv\n",
            "/kaggle/input/widsdatathon2024-challenge1/sample_submission.csv\n",
            "/kaggle/input/widsdatathon2024-challenge1/training.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of rows and columns\n",
        "print(\"Number of train samples are\",df_train.shape)\n",
        "print(\"Number of test samples are\",df_test.shape)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:47.812596Z",
          "iopub.execute_input": "2024-02-02T12:29:47.813069Z",
          "iopub.status.idle": "2024-02-02T12:29:47.81941Z",
          "shell.execute_reply.started": "2024-02-02T12:29:47.813028Z",
          "shell.execute_reply": "2024-02-02T12:29:47.818211Z"
        },
        "trusted": true,
        "id": "epS234Jo0KE5",
        "outputId": "d7fe7a30-bf10-40f0-aff3-b8554530784c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples are (12906, 83)\n",
            "Number of test samples are (5792, 82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text replacement"
      ],
      "metadata": {
        "id": "iG-MeDAYHw8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train_stemmed = df_train.copy()\n",
        "df_test_stemmed = df_test.copy()\n",
        "\n",
        "# Assuming df_train_data_imputed contains your DataFrame with the column 'A' containing sentence strings\n",
        "# Create a list of words to detect, including \"unspecified\" and \"unsp\"\n",
        "words_to_detect = [\"unsp\", \"right\", \"left\", \"upper\", \"outer\", \"overlap\", \"central\", \"axillary\", \"inner\", \"secondary\", \"nipple\"]\n",
        "# words_to_detect2 = [\"unspecified\", \"unsp\"]\n",
        "\n",
        "# Create a new column to represent the presence of any of the specified words\n",
        "for word in words_to_detect:\n",
        "        df_train_stemmed[word] = df_train_stemmed['breast_cancer_diagnosis_desc'].apply(lambda x: int(any(word in x.lower() for word in words_to_detect)))\n",
        "        df_test_stemmed[word] = df_test_stemmed['breast_cancer_diagnosis_desc'].apply(lambda x: int(any(word in x.lower() for word in words_to_detect)))\n",
        "\n",
        "# Now, df_train_data_imputed contains an additional column 'presence_of_any_word'\n",
        "df_train_stemmed = df_train_stemmed.drop(columns=\"breast_cancer_diagnosis_desc\")\n",
        "df_test_stemmed = df_test_stemmed.drop(columns=\"breast_cancer_diagnosis_desc\")\n",
        "\n",
        "df_train = df_train_stemmed\n",
        "df_test = df_test_stemmed\n"
      ],
      "metadata": {
        "id": "4PJlycHlFzAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Duplicate Records\n",
        "\n",
        "Duplicate records in a dataset can lead to inaccurate analysis by skewing results, causing data redundancy, and reducing the quality of insights. Identifying and removing these duplicates helps to ensure data integrity and reliability for accurate analysis.\n",
        "\n",
        "The duplicated() method returns a Boolean Series where each True represents a duplicate row, and the sum() method counts how many True values are there, effectively counting the duplicates."
      ],
      "metadata": {
        "id": "mCi1lITU0KE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_duplicates = df_train.duplicated().sum()\n",
        "\n",
        "print(\"Number of duplicate rows: \", num_duplicates)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.047846Z",
          "iopub.execute_input": "2024-02-02T12:29:50.048987Z",
          "iopub.status.idle": "2024-02-02T12:29:50.122442Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.048948Z",
          "shell.execute_reply": "2024-02-02T12:29:50.121369Z"
        },
        "trusted": true,
        "id": "G8B0wFjZ0KFA",
        "outputId": "b2884e80-a3bd-4a0e-9366-61e1a837f102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping Duplicate Records**\n",
        "\n",
        "Duplicates can be removed using pandas with the DataFrame.drop_duplicates() method. This method identifies and eliminates duplicate rows, keeping only the first occurrence of each unique record. Since for this dataset we found no duplicate records, the we don't use the drop_duplicates() method."
      ],
      "metadata": {
        "id": "Y89I9f5R0KFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_train.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.123675Z",
          "iopub.execute_input": "2024-02-02T12:29:50.124032Z",
          "iopub.status.idle": "2024-02-02T12:29:50.128609Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.124002Z",
          "shell.execute_reply": "2024-02-02T12:29:50.127412Z"
        },
        "trusted": true,
        "id": "A1Lgv_u30KFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Missing Values\n",
        "\n",
        "Checking for missing values is important because most machine learning algorithms assume data to be complete, and gaps can lead to incorrect analysis.\n",
        "\n",
        "\n",
        "Here we have a method check_missing_values() to analyze missing values in a pandas DataFrame.\n",
        "\n",
        "- Identify Missing Columns: It identifies which columns in the DataFrame contain any missing (NaN) values.\n",
        "\n",
        "- Count Missing Values: The function then calculates the total count of missing values for each column.\n",
        "\n",
        "- Summarize Missing Data: A new DataFrame is created, summarizing the count and percentage of missing values for each column.\n"
      ],
      "metadata": {
        "id": "HldoV2Ud0KFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_values(df):\n",
        "    missing_columns = [col for col in df.columns if df[col].isnull().any()]\n",
        "    missingvalues_count =df.isna().sum()\n",
        "    missingValues_df = pd.DataFrame(missingvalues_count.rename('Missing Values')).loc[missingvalues_count.ne(0)]\n",
        "    missingValues_df['Percentage'] = missingValues_df['Missing Values'] * 100 / df.shape[0]\n",
        "    return missingValues_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.130178Z",
          "iopub.execute_input": "2024-02-02T12:29:50.130509Z",
          "iopub.status.idle": "2024-02-02T12:29:50.136699Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.130479Z",
          "shell.execute_reply": "2024-02-02T12:29:50.135919Z"
        },
        "trusted": true,
        "id": "xybA0_Gn0KFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This summarized data is then sorted in descending order to get a clear overview of which columns have the most significant number of missing entries."
      ],
      "metadata": {
        "id": "M74H342S0KFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = check_missing_values(df_train)\n",
        "print(df.sort_values(by='Missing Values', ascending=False))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.137766Z",
          "iopub.execute_input": "2024-02-02T12:29:50.138456Z",
          "iopub.status.idle": "2024-02-02T12:29:50.180632Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.138414Z",
          "shell.execute_reply": "2024-02-02T12:29:50.179548Z"
        },
        "trusted": true,
        "id": "wsZH7P6M0KFB",
        "outputId": "4e13e592-bc68-47aa-a206-6eaca622367d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       Missing Values  Percentage\n",
            "metastatic_first_novel_treatment                12882   99.814040\n",
            "metastatic_first_novel_treatment_type           12882   99.814040\n",
            "bmi                                              8965   69.463815\n",
            "patient_race                                     6385   49.473113\n",
            "payer_type                                       1803   13.970246\n",
            "Region                                             52    0.402913\n",
            "Division                                           52    0.402913\n",
            "patient_state                                      51    0.395165\n",
            "PM25                                               29    0.224702\n",
            "Ozone                                              29    0.224702\n",
            "N02                                                29    0.224702\n",
            "income_household_75_to_100                          4    0.030993\n",
            "income_household_150_over                           4    0.030993\n",
            "income_household_15_to_20                           4    0.030993\n",
            "income_household_20_to_25                           4    0.030993\n",
            "income_household_25_to_35                           4    0.030993\n",
            "income_household_35_to_50                           4    0.030993\n",
            "income_household_50_to_75                           4    0.030993\n",
            "income_household_100_to_150                         4    0.030993\n",
            "income_household_six_figure                         4    0.030993\n",
            "income_household_under_5                            4    0.030993\n",
            "home_ownership                                      4    0.030993\n",
            "home_value                                          4    0.030993\n",
            "rent_median                                         4    0.030993\n",
            "rent_burden                                         4    0.030993\n",
            "farmer                                              4    0.030993\n",
            "self_employed                                       4    0.030993\n",
            "income_household_5_to_10                            4    0.030993\n",
            "income_household_10_to_15                           4    0.030993\n",
            "income_household_median                             4    0.030993\n",
            "family_dual_income                                  4    0.030993\n",
            "limited_english                                     4    0.030993\n",
            "poverty                                             4    0.030993\n",
            "family_size                                         4    0.030993\n",
            "race_native                                         1    0.007748\n",
            "race_white                                          1    0.007748\n",
            "labor_force_participation                           1    0.007748\n",
            "unemployment_rate                                   1    0.007748\n",
            "population                                          1    0.007748\n",
            "density                                             1    0.007748\n",
            "veteran                                             1    0.007748\n",
            "health_uninsured                                    1    0.007748\n",
            "commute_time                                        1    0.007748\n",
            "education_college_or_above                          1    0.007748\n",
            "race_pacific                                        1    0.007748\n",
            "race_black                                          1    0.007748\n",
            "disabled                                            1    0.007748\n",
            "hispanic                                            1    0.007748\n",
            "race_asian                                          1    0.007748\n",
            "race_multiple                                       1    0.007748\n",
            "race_other                                          1    0.007748\n",
            "education_stem_degree                               1    0.007748\n",
            "age_under_10                                        1    0.007748\n",
            "education_graduate                                  1    0.007748\n",
            "education_bachelors                                 1    0.007748\n",
            "age_20s                                             1    0.007748\n",
            "age_30s                                             1    0.007748\n",
            "age_40s                                             1    0.007748\n",
            "age_50s                                             1    0.007748\n",
            "age_60s                                             1    0.007748\n",
            "age_70s                                             1    0.007748\n",
            "age_over_80                                         1    0.007748\n",
            "male                                                1    0.007748\n",
            "female                                              1    0.007748\n",
            "married                                             1    0.007748\n",
            "divorced                                            1    0.007748\n",
            "never_married                                       1    0.007748\n",
            "widowed                                             1    0.007748\n",
            "age_median                                          1    0.007748\n",
            "income_individual_median                            1    0.007748\n",
            "age_10_to_19                                        1    0.007748\n",
            "education_less_highschool                           1    0.007748\n",
            "education_highschool                                1    0.007748\n",
            "education_some_college                              1    0.007748\n",
            "housing_units                                       1    0.007748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Missing Data"
      ],
      "metadata": {
        "id": "Zjp-GAsw0KFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_dropped_columns = df_train.drop(columns=df_train.columns[df_train.isnull().mean() > 0.3])\n",
        "\n",
        "print(\"No. of columns before dropping: \", df_train.shape[1] )\n",
        "print(\"No. of columns after dropping: \", df_train_dropped_columns.shape[1] )\n",
        "print(df_train.shape[1]- df_train_dropped_columns.shape[1],\" columns dropped\")\n",
        "\n",
        "# Identify which columns were dropped\n",
        "dropped_columns = df_train.columns.difference(df_train_dropped_columns.columns)\n",
        "\n",
        "print(dropped_columns)\n",
        "\n",
        "df_test_dropped_columns = df_test.drop(columns=dropped_columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.200081Z",
          "iopub.execute_input": "2024-02-02T12:29:50.201147Z",
          "iopub.status.idle": "2024-02-02T12:29:50.225088Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.201105Z",
          "shell.execute_reply": "2024-02-02T12:29:50.223973Z"
        },
        "trusted": true,
        "id": "HAcB9F2v0KFC",
        "outputId": "a55a789c-8b81-41f0-f749-c03a01e2b7f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of columns before dropping:  93\n",
            "No. of columns after dropping:  89\n",
            "4  columns dropped\n",
            "Index(['bmi', 'metastatic_first_novel_treatment',\n",
            "       'metastatic_first_novel_treatment_type', 'patient_race'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we again check for missing values in the modified train set.\n",
        "\n"
      ],
      "metadata": {
        "id": "_I8xWRFz0KFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set shape: \",df_train_dropped_columns.shape)\n",
        "print(\"Test set shape: \",df_test_dropped_columns.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09uTTYOyDYqk",
        "outputId": "17ed81b8-1098-4ec7-a3a3-a6cf2117e2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape:  (12906, 89)\n",
            "Test set shape:  (5792, 88)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputation"
      ],
      "metadata": {
        "id": "WmddSPMa_5bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_data = df_train_dropped_columns.drop('DiagPeriodL90D', axis=1)\n",
        "df_train_labels = df_train_dropped_columns['DiagPeriodL90D']\n",
        "\n",
        "df_test_data = df_test_dropped_columns.copy()\n"
      ],
      "metadata": {
        "id": "6RP0IntMnIoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Combine df_train_data and df_test\n",
        "combined_data = pd.concat([df_train_data, df_test_data], axis=0)\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "numerical_cols = combined_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = combined_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Initialize KNN imputer for numerical features\n",
        "numerical_imputer = KNNImputer(n_neighbors=3)  # You can adjust the number of neighbors\n",
        "\n",
        "# Impute numerical features\n",
        "combined_data[numerical_cols] = numerical_imputer.fit_transform(combined_data[numerical_cols])\n",
        "\n",
        "# Fill \"Missing\" for categorical features\n",
        "combined_data[categorical_cols] = combined_data[categorical_cols].fillna(\"Missing\")\n",
        "\n",
        "# Split the combined data back into df_train_data and df_test\n",
        "df_train_data_imputed = combined_data.iloc[:len(df_train_data)]\n",
        "df_test_data_imputed = combined_data.iloc[len(df_train_data):]\n",
        "\n",
        "# Now, df_train_data_imputed and df_test_imputed contain imputed values for both numerical and categorical features\n",
        "\n"
      ],
      "metadata": {
        "id": "zDlc3Roei66l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the shapes of train and test set\n",
        "print(\"Train set shape: \",df_train_data_imputed.shape)\n",
        "print(\"Test set shape: \",df_test_data_imputed.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.322431Z",
          "iopub.execute_input": "2024-02-02T12:29:50.323081Z",
          "iopub.status.idle": "2024-02-02T12:29:50.329408Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.323048Z",
          "shell.execute_reply": "2024-02-02T12:29:50.328059Z"
        },
        "trusted": true,
        "id": "DVc0Ab8a0KFK",
        "outputId": "d850f5ac-3588-4b90-adb5-f3aa2ae9663e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape:  (12906, 88)\n",
            "Test set shape:  (5792, 88)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isolating Outliers"
      ],
      "metadata": {
        "id": "WD8oQhwqvRs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Concatenate df_train_data_scaled with df_train_labels_balanced\n",
        "combined_data = pd.concat([df_train_data_imputed, df_train_labels], axis=1)\n",
        "\n",
        "# Select only the numeric features\n",
        "num_train = combined_data.select_dtypes('number')\n",
        "\n",
        "# Initialize Isolation Forest\n",
        "iso = IsolationForest(contamination=0.01)\n",
        "\n",
        "# Apply Isolation Forest to identify outliers\n",
        "outliers = iso.fit_predict(num_train)\n",
        "\n",
        "# Identify the indices of outliers in the original dataset\n",
        "outlier_indices = num_train.index[outliers == -1]\n",
        "\n",
        "# Display the rows that were removed (outliers)\n",
        "removed_rows = combined_data.loc[outlier_indices]\n",
        "print(\"Removed Rows (Outliers):\")\n",
        "print(removed_rows)\n",
        "\n",
        "# Create a new DataFrame df_train_data_isolated without outliers\n",
        "df_train_isolated = combined_data[outliers != -1]\n",
        "\n",
        "# Separate the feature data and labels\n",
        "df_train_labels_isolated = df_train_isolated['DiagPeriodL90D']  # Extract the labels\n",
        "df_train_data_isolated = df_train_isolated.drop(columns=['DiagPeriodL90D'])  # Remove the label column\n",
        "\n",
        "# Now df_train_data_isolated contains the feature data without outliers, and df_train_labels_isolated contains the corresponding labels.\n"
      ],
      "metadata": {
        "id": "nXWo6u2WvR8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for Imbalanced Classes\n",
        "\n",
        "Class imbalance can significantly impact the performance of machine learning models, leading to biased predictions favoring the majority class. Hence, it is important to identify and address this to ensure accurate and fair model outcomes.\n",
        "\n",
        "A common guideline is to consider a dataset imbalanced if the minority class constitutes less than 20% of the total data. However, this threshold can vary based on specific domain requirements and the nature of the dataset."
      ],
      "metadata": {
        "id": "a2gi_JDY0KFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def check_class_distribution(df):\n",
        "\n",
        "    # Count the number of classes\n",
        "    class_counts = df.value_counts()\n",
        "\n",
        "    # Display the number of instances per class\n",
        "    print(\"No. of instances per class\")\n",
        "    print(class_counts)\n",
        "\n",
        "    # Plotting the bar graph for class distribution\n",
        "    plt.bar(class_counts.index, class_counts.values)\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "check_class_distribution(df_train_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.331262Z",
          "iopub.execute_input": "2024-02-02T12:29:50.331592Z",
          "iopub.status.idle": "2024-02-02T12:29:50.781844Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.331547Z",
          "shell.execute_reply": "2024-02-02T12:29:50.780744Z"
        },
        "trusted": true,
        "id": "WEi7ywn00KFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Class Imbalance\n",
        "Here class 1 is the majority class and class 0 is the minority class. Whether the data is imbalanced depends on your specific dataset. One naive approach to balance a dataset is by randomly undersampling the majority class. This involves randomly removing some instances from the majority class to match the number of instances in the minority class.  "
      ],
      "metadata": {
        "id": "sldv5hNM0KFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df_train_data_imputed contains your feature data and df_train_labels contains your labels\n",
        "# Combine the feature data and labels into one DataFrame\n",
        "balanced_df = pd.concat([df_train_data_isolated, df_train_labels_isolated], axis=1)\n",
        "\n",
        "# Separate the data into two DataFrames based on the class labels\n",
        "class_0 = balanced_df[balanced_df['DiagPeriodL90D'] == 0]\n",
        "class_1 = balanced_df[balanced_df['DiagPeriodL90D'] == 1]\n",
        "\n",
        "# Calculate the ratio of samples in class 0 to class 1\n",
        "class_0_count = len(class_0)\n",
        "class_1_count = len(class_1)\n",
        "ratio = class_0_count / class_1_count\n",
        "\n",
        "# Duplicate rows from class 1 to balance the dataset\n",
        "if ratio < 1:\n",
        "    duplicates_needed = int(class_1_count - class_0_count)\n",
        "    duplicates = class_0.sample(n=duplicates_needed, replace=True, random_state=42)\n",
        "    class_0_balanced = pd.concat([class_0, duplicates])\n",
        "    balanced_df = pd.concat([class_1, class_0_balanced])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Separate the balanced dataset back into feature data and labels\n",
        "df_train_data_balanced = balanced_df.drop(columns=['DiagPeriodL90D'])\n",
        "df_train_labels_balanced = balanced_df['DiagPeriodL90D']\n",
        "\n",
        "# Now df_train_data_balanced and df_train_labels_balanced contain the balanced dataset\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:50.785613Z",
          "iopub.execute_input": "2024-02-02T12:29:50.785977Z",
          "iopub.status.idle": "2024-02-02T12:29:50.815232Z",
          "shell.execute_reply.started": "2024-02-02T12:29:50.785946Z",
          "shell.execute_reply": "2024-02-02T12:29:50.813981Z"
        },
        "trusted": true,
        "id": "j8RZCG1o0KFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dyks5PO-wquf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical Vaiables"
      ],
      "metadata": {
        "id": "zpYRS0TB0KFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df_train_data_imputed and df_test_data_imputed contain your data\n",
        "# Concatenate the train and test datasets to ensure consistent one-hot encoding\n",
        "combined_imputed_data = pd.concat([df_train_data_balanced, df_test_data_imputed], axis=0)\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "numerical_cols = combined_imputed_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = combined_imputed_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "combined_data_encoded = pd.get_dummies(combined_imputed_data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Split the combined data back into train and test datasets\n",
        "df_train_data_encoded = combined_data_encoded.iloc[:len(df_train_data_balanced)]\n",
        "df_test_data_encoded = combined_data_encoded.iloc[len(df_train_data_balanced):]\n",
        "\n",
        "# Now, train_data_encoded and test_data_encoded contain one-hot encoded features\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:51.062959Z",
          "iopub.execute_input": "2024-02-02T12:29:51.063287Z",
          "iopub.status.idle": "2024-02-02T12:29:51.103624Z",
          "shell.execute_reply.started": "2024-02-02T12:29:51.063258Z",
          "shell.execute_reply": "2024-02-02T12:29:51.102537Z"
        },
        "trusted": true,
        "id": "776QACUQ0KFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_data_encoded.to_csv(path + 'df_train_data_encoded.csv', index = False)"
      ],
      "metadata": {
        "id": "cfEZpgoqF64C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "v-UiEm8N6xA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### MinMax Scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mnscaler = MinMaxScaler()\n",
        "df_train_data_scaled = mnscaler.fit_transform(df_train_data_encoded)\n",
        "\n",
        "df_test_data_scaled = mnscaler.transform(df_test_data_encoded)\n"
      ],
      "metadata": {
        "id": "9TuZoFw66wTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**balancing(not using)**"
      ],
      "metadata": {
        "id": "6WXq2zFR3Nqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df_train_data_scaled and df_train_labels are your data and labels dataframes\n",
        "# Combine the data and labels into a single dataframe\n",
        "balanced_df = pd.concat([pd.DataFrame(df_train_data_scaled), pd.Series(df_train_labels)], axis=1)\n",
        "\n",
        "# Separate the data into two dataframes based on the label\n",
        "df_label_0 = balanced_df[balanced_df['DiagPeriodL90D'] == 0]\n",
        "df_label_1 = balanced_df[balanced_df['DiagPeriodL90D'] == 1]\n",
        "\n",
        "# Calculate the difference in counts between the two classes\n",
        "count_label_0 = len(df_label_0)\n",
        "count_label_1 = len(df_label_1)\n",
        "count_difference = count_label_1 - count_label_0\n",
        "\n",
        "# Duplicate rows from the dataframe with label 1 to balance the classes\n",
        "if count_difference > 0:\n",
        "    # Randomly sample rows from df_label_1 with replacement to match the count\n",
        "    duplicated_rows = df_label_0.sample(n=count_difference, replace=True, random_state=42)\n",
        "    # Concatenate the duplicated rows with the original data\n",
        "    balanced_df = pd.concat([df_label_0, df_label_1, duplicated_rows], axis=0)\n",
        "\n",
        "# Separate the balanced dataframe back into data and labels\n",
        "df_train_data_balanced = balanced_df.drop(columns=['DiagPeriodL90D'])\n",
        "df_train_labels_balanced = balanced_df['DiagPeriodL90D']\n",
        "\n",
        "# Now, df_train_data_balanced and df_train_labels_balanced contain balanced data\n"
      ],
      "metadata": {
        "id": "Y4aMp_0p3MjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train test split(not using)**"
      ],
      "metadata": {
        "id": "WGuv-AMX4WUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Train test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train_data_scaled, df_train_labels_balanced, test_size=0.1, random_state = random_seed)\n",
        "\n",
        "X_train = torch.Tensor(X_train)\n",
        "y_train = torch.Tensor(y_train.to_numpy())\n",
        "\n",
        "X_test = torch.Tensor(X_test)\n",
        "y_test = torch.Tensor(y_test.to_numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:29:51.12961Z",
          "iopub.execute_input": "2024-02-02T12:29:51.130407Z",
          "iopub.status.idle": "2024-02-02T12:29:51.145137Z",
          "shell.execute_reply.started": "2024-02-02T12:29:51.130375Z",
          "shell.execute_reply": "2024-02-02T12:29:51.144056Z"
        },
        "trusted": true,
        "id": "DPYIBxhh0KFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "uoEOevv37yX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP + MSELoss"
      ],
      "metadata": {
        "id": "vNHKs4hH72f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, MSELoss, Linear, Dropout\n",
        "from torch.optim import SGD\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "def threshold_tensor(tensor, threshold=0.5):\n",
        "    return (tensor > threshold).float()\n",
        "\n",
        "class Basic_MLP_Model(torch.nn.Module):\n",
        "      def __init__(self, input_size, hidden_size, output_size):\n",
        "            \"\"\" input_layer: 1 number,\n",
        "                hidden_layer: a list of numbers nominating the hidden_layer size.\n",
        "                              for example, [2,3,4,5]\n",
        "                output_layer: size of output neurals\n",
        "\n",
        "            \"\"\"\n",
        "            super().__init__()\n",
        "\n",
        "            if len(hidden_size) <= 0:\n",
        "                raise ValueError(\"too few hidden layers \")\n",
        "\n",
        "\n",
        "            self.num_layers = len(hidden_size) + 2\n",
        "            self.input_layer = Linear(input_size, hidden_size[0])\n",
        "\n",
        "            self.hidden_layers = [Linear(hidden_size[i-1], hidden_size[i]) for i in range(1,len(hidden_size),1)]\n",
        "            self.output_layer = Linear(hidden_size[-1], output_size)\n",
        "\n",
        "            self.dropout = Dropout(p=0.1)\n",
        "            self.relu = torch.nn.functional.relu\n",
        "            self.sigmoid = torch.nn.functional.sigmoid\n",
        "\n",
        "      def forward(self, X):\n",
        "\n",
        "            ### input layer\n",
        "            X = self.dropout(self.relu(self.input_layer(X)))\n",
        "\n",
        "            ### hidden layer\n",
        "            for layer in self.hidden_layers:\n",
        "                  X = self.dropout(self.relu(layer(X)))\n",
        "\n",
        "            ### output layer\n",
        "            X = self.output_layer(X)\n",
        "            X = self.sigmoid(X)\n",
        "            return X\n"
      ],
      "metadata": {
        "id": "j6cnX43K7xs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP feedforward"
      ],
      "metadata": {
        "id": "7aPIi0kdVBb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, MSELoss, Linear, Dropout\n",
        "from torch.optim import SGD\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "class FeedforwardMLP_Model(torch.nn.Module):\n",
        "      def __init__(self, input_size, hidden_size, feedforward_size, output_size = [128, 64, 1]):\n",
        "            \"\"\" input_size: 1 number,\n",
        "                hidden_size: a list of numbers nominating the hidden_layer size.\n",
        "                              for example, [2,3,4,5]\n",
        "                feedforward_size: a list of numbers nominating the feedforward_layer size, but has to be the same.\n",
        "                              for example, [5,5,5,5]\n",
        "                output_size: 3 numbers nominating the output_layer size.\n",
        "                              for example, [2,3,4,5]\n",
        "\n",
        "            \"\"\"\n",
        "            super().__init__()\n",
        "\n",
        "            if len(hidden_size) <= 0:\n",
        "                raise ValueError(\"too few hidden layers \")\n",
        "\n",
        "\n",
        "            self.num_layers = len(hidden_size) + 2\n",
        "            self.input_layer = Linear(input_size, hidden_size[0])\n",
        "\n",
        "            self.hidden_layers = [Linear(hidden_size[i-1], hidden_size[i]) for i in range(1,len(hidden_size),1)]\n",
        "\n",
        "            self.transit_layer = Linear(hidden_size[-1], feedforward_size[0])\n",
        "\n",
        "            self.feedforward_layers = [Linear(feedforward_size[i-1], feedforward_size[i]) for i in range(1,len(feedforward_size),1)]\n",
        "\n",
        "            self.output_layer1 = Linear(feedforward_size[-1], output_size[0])\n",
        "            self.output_layer2 = Linear(output_size[0], output_size[1])\n",
        "            self.output_layer3 = Linear(output_size[1], output_size[2])\n",
        "\n",
        "            self.dropout = Dropout(p=0.1)\n",
        "            self.relu = torch.nn.functional.relu\n",
        "            self.sigmoid = torch.nn.functional.sigmoid\n",
        "\n",
        "      def forward(self, X):\n",
        "\n",
        "            ### input layer\n",
        "            X = self.dropout(self.relu(self.input_layer(X)))\n",
        "\n",
        "            ### hidden layer\n",
        "            for layer in self.hidden_layers:\n",
        "                  X = self.dropout(self.relu(layer(X)))\n",
        "\n",
        "            X = self.relu(self.transit_layer(X))\n",
        "\n",
        "            ### feedforward layer\n",
        "            for layer in self.feedforward_layers:\n",
        "                  X = self.dropout(self.relu(layer(X))) + X\n",
        "\n",
        "            ### output layer\n",
        "            X = self.relu(self.output_layer1(X))\n",
        "            X = self.relu(self.output_layer2(X))\n",
        "            X = self.output_layer3(X)\n",
        "            X = self.sigmoid(X)\n",
        "            return X\n"
      ],
      "metadata": {
        "id": "aE11gNqDceW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "40VPG1CMEru4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.Tensor(torch.Tensor(df_train_data_scaled))\n",
        "labels = torch.Tensor(torch.Tensor(df_train_labels_balanced))\n",
        "\n",
        "input_size = features.shape[1]\n",
        "hidden_size = [512, 1024, 256]\n",
        "feedforward_size = [512, 512, 512]\n",
        "output_size = 1\n",
        "\n",
        "model = Basic_MLP_Model(input_size, hidden_size, output_size)\n",
        "\n",
        "###################333\n",
        "\n",
        "from torch.utils.data.dataset import random_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "num_samples = features.shape[0]\n",
        "num_train_samples = int(num_samples * 0.9)\n",
        "num_val_samples = num_samples - num_train_samples\n",
        "\n",
        "train_dataset, val_dataset = random_split(TensorDataset(features, labels), [num_train_samples, num_val_samples],\\\n",
        "                                          generator = torch.Generator().manual_seed(random_seed))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, generator = torch.Generator().manual_seed(random_seed))\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)  # No need to shuffle validation data"
      ],
      "metadata": {
        "id": "29FaO3hoQ-Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_predictions = []  # Store predicted probabilities\n",
        "    val_targets = []  # Store true labels\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze()\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Store predicted probabilities and true labels\n",
        "            val_predictions.extend(outputs.cpu().numpy())\n",
        "            val_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate AUC for validation\n",
        "    val_auc = roc_auc_score(val_targets, val_predictions)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss / len(val_loader)}, Validation AUC: {val_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4eDfMDSQaDs",
        "outputId": "f2200b60-6f05-4b3e-91b1-211703dda56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Training Loss: 0.1662865872156015\n",
            "Epoch 1/10, Validation Loss: 0.16779877168066318, Validation AUC: 0.7962\n",
            "Epoch 2/10, Training Loss: 0.1660922453732319\n",
            "Epoch 2/10, Validation Loss: 0.16796323961968865, Validation AUC: 0.7959\n",
            "Epoch 3/10, Training Loss: 0.16584878675210749\n",
            "Epoch 3/10, Validation Loss: 0.167866109778513, Validation AUC: 0.7970\n",
            "Epoch 4/10, Training Loss: 0.16556861105705364\n",
            "Epoch 4/10, Validation Loss: 0.16774699582704447, Validation AUC: 0.7969\n",
            "Epoch 5/10, Training Loss: 0.16471341074251067\n",
            "Epoch 5/10, Validation Loss: 0.1704364794505201, Validation AUC: 0.7942\n",
            "Epoch 6/10, Training Loss: 0.1645966405107158\n",
            "Epoch 6/10, Validation Loss: 0.16833407687665733, Validation AUC: 0.7974\n",
            "Epoch 7/10, Training Loss: 0.16403065973735145\n",
            "Epoch 7/10, Validation Loss: 0.16986876397992187, Validation AUC: 0.7959\n",
            "Epoch 8/10, Training Loss: 0.1640161457191844\n",
            "Epoch 8/10, Validation Loss: 0.1684969402809232, Validation AUC: 0.7995\n",
            "Epoch 9/10, Training Loss: 0.16348649199292767\n",
            "Epoch 9/10, Validation Loss: 0.1679813095470128, Validation AUC: 0.7991\n",
            "Epoch 10/10, Training Loss: 0.16335944008651593\n",
            "Epoch 10/10, Validation Loss: 0.16902274657364372, Validation AUC: 0.7973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to track test loss and accuracy\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# No gradient calculations needed\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)  # Get model predictions for the test set\n",
        "    outputs = outputs.squeeze()  # Remove extra dimensions if any\n",
        "    loss = criterion(outputs, y_test.float())  # Calculate loss\n",
        "    test_loss = loss.item()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
        "    total += y_test.size(0)\n",
        "    correct += (predicted == y_test).sum().item()\n",
        "\n",
        "test_accuracy = correct / total\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "NB5l6WZAU19d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Combine predictions and true labels into a DataFrame\n",
        "result_df = pd.DataFrame({'True_Labels': y_test, 'Predicted_Labels': predicted})\n",
        "\n",
        "# Identify mispredictions by comparing true labels with predicted labels\n",
        "misclassified_rows = result_df[result_df['True_Labels'] != result_df['Predicted_Labels']]\n",
        "\n",
        "# Print the misclassified rows\n",
        "print(\"Misclassified Rows:\")\n",
        "print(misclassified_rows)\n",
        "\n",
        "# If you want to see the corresponding data for the misclassified rows, you can merge with your original data\n",
        "# Assuming df_train_data_imputed contains your feature data\n",
        "misclassified_data = df_train_data_imputed.loc[misclassified_rows.index]\n",
        "\n",
        "# Print the misclassified data\n",
        "print(\"Misclassified Data:\")\n",
        "print(misclassified_data)\n"
      ],
      "metadata": {
        "id": "zNTpS4f4qMPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified_data.to_csv(path + 'misclassified.csv')"
      ],
      "metadata": {
        "id": "kA6xhcOIqjLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "OYqXC9Hf0KFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cross_validation.png](attachment:db6a3093-d295-49aa-864c-92f206f72f1e.png)"
      ],
      "metadata": {
        "id": "Nzp8cOM40KFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for details on cross-validation [here](https://scikit-learn.org/stable/modules/cross_validation.html)"
      ],
      "metadata": {
        "id": "6UEGQjki0KFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "#Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation score:\", cv_scores.mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:30:02.105455Z",
          "iopub.execute_input": "2024-02-02T12:30:02.105785Z",
          "iopub.status.idle": "2024-02-02T12:30:46.125377Z",
          "shell.execute_reply.started": "2024-02-02T12:30:02.105756Z",
          "shell.execute_reply": "2024-02-02T12:30:46.123847Z"
        },
        "trusted": true,
        "id": "7N55xDYJ0KFN",
        "outputId": "19c25b56-771e-4a54-8cca-568cb19e3615"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cross-validation scores: [0.51857247 0.52367079 0.50764749 0.53095412 0.49125364]\nMean cross-validation score: 0.5144197019146854\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_val)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "confusion = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:30:46.12725Z",
          "iopub.execute_input": "2024-02-02T12:30:46.128094Z",
          "iopub.status.idle": "2024-02-02T12:30:46.163725Z",
          "shell.execute_reply.started": "2024-02-02T12:30:46.128046Z",
          "shell.execute_reply": "2024-02-02T12:30:46.162466Z"
        },
        "trusted": true,
        "id": "FqzPuSFT0KFN",
        "outputId": "5b3d2626-08ed-453e-f5c4-d2bfcd6e2b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.5081585081585082\nPrecision: 0.5052770448548812\nRecall: 0.4495305164319249\nF1 Score: 0.4757763975155279\nConfusion Matrix:\n [[489 375]\n [469 383]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train for full data"
      ],
      "metadata": {
        "id": "UUCINHi7k8UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size = [128,256,64]\n",
        "output_size = 1\n",
        "\n",
        "final_model = Basic_MLP_Model(input_size, hidden_size, output_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5RiIw06k8dr",
        "outputId": "f34a4149-f96e-4e41-dc5d-3707bf75e9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5230],\n",
              "        [0.5239],\n",
              "        [0.5223],\n",
              "        ...,\n",
              "        [0.5216],\n",
              "        [0.5204],\n",
              "        [0.5213]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "num_samples = X_train.shape[0]\n",
        "num_train_samples = int(num_samples * 0.8)\n",
        "num_val_samples = num_samples - num_train_samples\n",
        "\n",
        "train_dataset, val_dataset = random_split(TensorDataset(X_train, y_train), [num_train_samples, num_val_samples],\\\n",
        "                                          generator = torch.Generator().manual_seed(random_seed))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, generator = torch.Generator().manual_seed(random_seed))\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)  # No need to shuffle validation data"
      ],
      "metadata": {
        "id": "AVe4FiFllb1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = [128,256,64]\n",
        "output_size = 1\n",
        "\n",
        "final_model = Basic_MLP_Model(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.0001)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# Assuming X_train and y_train are PyTorch tensors\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.Tensor(df_train_data_scaled), torch.Tensor(df_train_labels.values)), batch_size=8, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    final_model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swFCSsLDmG5p",
        "outputId": "7c9404cd-1813-45c7-94d4-2b43f7ef73b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Training Loss: 0.19884292028447362\n",
            "Epoch 2/20, Training Loss: 0.17376234148348574\n",
            "Epoch 3/20, Training Loss: 0.16000412965408045\n",
            "Epoch 4/20, Training Loss: 0.15476621874484617\n",
            "Epoch 5/20, Training Loss: 0.15258866579351482\n",
            "Epoch 6/20, Training Loss: 0.15144395472567246\n",
            "Epoch 7/20, Training Loss: 0.150705081242214\n",
            "Epoch 8/20, Training Loss: 0.15008421433117827\n",
            "Epoch 9/20, Training Loss: 0.14997922711575212\n",
            "Epoch 10/20, Training Loss: 0.14951808050694926\n",
            "Epoch 11/20, Training Loss: 0.14950109080929663\n",
            "Epoch 12/20, Training Loss: 0.1490955742426872\n",
            "Epoch 13/20, Training Loss: 0.1487330167243878\n",
            "Epoch 14/20, Training Loss: 0.14825424606666024\n",
            "Epoch 15/20, Training Loss: 0.14828296410453032\n",
            "Epoch 16/20, Training Loss: 0.14819497527506162\n",
            "Epoch 17/20, Training Loss: 0.14839431949426066\n",
            "Epoch 18/20, Training Loss: 0.14825063532096008\n",
            "Epoch 19/20, Training Loss: 0.14807807553393357\n",
            "Epoch 20/20, Training Loss: 0.14794045076111176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Guide\n",
        "\n",
        "Once we have the final model, we will use it to predict on our test set *df_test*\n",
        "\n"
      ],
      "metadata": {
        "id": "FGxVrt6V0KFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "# No gradient calculations needed\n",
        "with torch.no_grad():\n",
        "    outputs = model(torch.Tensor(df_test_data_scaled))  # Get model predictions for the test set\n",
        "    outputs = outputs.squeeze()  # Remove extra dimensions if any\n",
        "\n",
        "### no need for this\n",
        "#predictions = (outputs > 0.5).float()\n",
        "predictions = outputs\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'patient_id': df_test['patient_id'],\n",
        "    'DiagPeriodL90D': predictions\n",
        "})\n",
        "submission_df.head()\n",
        "\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "csv_file_path = path + 'submission.csv'\n",
        "submission_df.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-02T12:30:46.165416Z",
          "iopub.execute_input": "2024-02-02T12:30:46.166293Z",
          "iopub.status.idle": "2024-02-02T12:30:46.178498Z",
          "shell.execute_reply.started": "2024-02-02T12:30:46.166246Z",
          "shell.execute_reply": "2024-02-02T12:30:46.177287Z"
        },
        "trusted": true,
        "id": "cIN-TAlW0KFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submissions are made on Kaggle in the form of CSV files where there will be two columns, the ID of the instance (Here patient_id) and predicted value.\n",
        "\n",
        "Note: Check the sample_submission.csv"
      ],
      "metadata": {
        "id": "Se4k1RJb0KFO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soUyMcOanV7O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}